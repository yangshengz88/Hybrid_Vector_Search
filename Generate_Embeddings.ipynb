{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Generation Pipeline\n",
    "\n",
    "To support similarity search over the Spotify dataset, we construct a compact 14-dimensional embedding that incorporates acoustic features, lightweight metadata, and temporal information. This embedding is derived from the cleaned and normalized dataset produced during preprocessing.\n",
    "\n",
    "We begin by selecting ten core audio features—such as danceability, energy, valence, tempo, and acousticness—and standardize them to ensure a consistent numerical scale. To better reflect musical intuition, we apply domain-inspired feature weights that emphasize rhythmic and energetic attributes while down-weighting features that are less influential for similarity (e.g., liveness, loudness).\n",
    "\n",
    "Next, we integrate a small set of categorical attributes (key, mode, explicit flag), providing additional structure related to harmony and lyrical content without significantly expanding dimensionality. We also include a standardized release-year feature to capture temporal trends in music pro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: (169776, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load cleaned dataset\n",
    "spotify = pd.read_parquet(\"data/spotify_clean.parquet\")\n",
    "print(\"Loaded dataset:\", spotify.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Core Audio Features for Embedding Construction\n",
    "# We define the set of normalized acoustic features—including danceability, energy, valence, tempo, and others—that form the foundation of our music similarity embedding. These 10 features capture the core timbre, rhythm, and mood characteristics of each track.\n",
    "\n",
    "audio_features = [\n",
    "    'danceability', 'energy', 'valence', 'tempo', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'speechiness', 'loudness', 'popularity'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric matrix: (169776, 10)\n"
     ]
    }
   ],
   "source": [
    "# We standardize all audio features using `StandardScaler` to ensure they share a comparable numerical scale. This prevents high-variance features from dominating the embedding and improves stability of similarity computations.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(spotify[audio_features]).astype(\"float32\")\n",
    "print(\"Numeric matrix:\", Z.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Domain-Inspired Feature Weights\n",
    "We introduce manual feature weights to emphasize certain musical characteristics (e.g., danceability and energy) while down-weighting others (e.g., liveness, loudness). This produces a weighted audio vector that better aligns with intuitive music similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted audio embeddings: (169776, 10)\n"
     ]
    }
   ],
   "source": [
    "# Feature weights tuned for music similarity\n",
    "weights = np.array([\n",
    "    1.2,  # danceability\n",
    "    1.2,  # energy\n",
    "    1.0,  # valence\n",
    "    1.0,  # tempo\n",
    "    0.8,  # acousticness\n",
    "    0.8,  # instrumentalness\n",
    "    0.7,  # liveness\n",
    "    0.6,  # speechiness\n",
    "    0.5,  # loudness\n",
    "    1.0   # popularity\n",
    "], dtype=\"float32\")\n",
    "\n",
    "Z_weighted = Z * weights\n",
    "print(\"Weighted audio embeddings:\", Z_weighted.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical matrix: (169776, 3)\n"
     ]
    }
   ],
   "source": [
    "# Lightweight categorical metadata included in embedding\n",
    "cat_cols = [\"key\", \"mode\", \"explicit\"]\n",
    "cat_emb = spotify[cat_cols].astype(\"float32\").values\n",
    "\n",
    "print(\"Categorical matrix:\", cat_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year matrix: (169776, 1)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the year column\n",
    "year_scaled = StandardScaler().fit_transform(spotify[['year']]).astype(\"float32\")\n",
    "print(\"Year matrix:\", year_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final embedding matrix shape: (169776, 14)\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.concatenate([Z_weighted, cat_emb, year_scaled], axis=1).astype(\"float32\")\n",
    "print(\"Final embedding matrix shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to data/spotify_vectors_14d.npy\n",
      "Saved ID-to-index mapping.\n"
     ]
    }
   ],
   "source": [
    "np.save(\"data/spotify_vectors_14d.npy\", embeddings)\n",
    "print(\"Saved embeddings to data/spotify_vectors_14d.npy\")\n",
    "\n",
    "# Track ID → row index mapping\n",
    "id_to_index = {tid: i for i, tid in enumerate(spotify[\"id\"])}\n",
    "json.dump(id_to_index, open(\"data/id_to_index.json\", \"w\"))\n",
    "\n",
    "print(\"Saved ID-to-index mapping.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
